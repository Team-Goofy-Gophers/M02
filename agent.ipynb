{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b3a36d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, List, Annotated, Union\n",
    "from langgraph.graph.message import add_messages\n",
    "from google import genai\n",
    "import dotenv, os\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from model.db import chroma_client\n",
    "from google.genai import types\n",
    "import requests, json\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b6fc5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",temperature=0.7\n",
    ")\n",
    "server_url = \"http://147.93.29.19:9876\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "34da0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionState(TypedDict):\n",
    "    id: str ## unique identifier for the session as well as collection name\n",
    "    session_name: str ## name of the session\n",
    "    \n",
    "    feedback: Annotated[List[dict], add_messages]\n",
    "    messages: Annotated[List[dict], add_messages]\n",
    "    \n",
    "    invoke: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c0b2e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interface_agent(state: SessionState):\n",
    "    print(state.get(\"invoke\"))\n",
    "    if state.get(\"invoke\") == \"message\":\n",
    "        state[\"invoke\"] = \"classify\"\n",
    "        return {\n",
    "            \"next_nodes\": [\"user_message_classifier\"],  # Specify the next node(s)\n",
    "            \"state\": state  # Return the updated state\n",
    "        }\n",
    "    \n",
    "    if state.get(\"invoke\") == \"ExtractData\":\n",
    "        state[\"invoke\"] = \"schema_definer\"\n",
    "        return {\n",
    "            \"next_nodes\": [\"schema_definer\"],  # Specify the next node(s)\n",
    "            \"state\": state  # Return the updated state\n",
    "        }\n",
    "        \n",
    "    if state.get(\"invoke\") == \"extract_data\":\n",
    "        return {\n",
    "            \"next_nodes\": [\"extract_data\"],  # Specify the next node(s)\n",
    "            \"state\": state  # Return the updated state\n",
    "        }\n",
    "        \n",
    "    if state.get(\"invoke\") == \"done\":\n",
    "        return {\n",
    "            \"next_nodes\": [END],  # Indicate the end of the graph\n",
    "            \"state\": state  # Return the updated state\n",
    "        }\n",
    "        \n",
    "    if state.get(\"invoke\") == \"SuggestOrCreateSchema\":\n",
    "        return {\n",
    "            \"next_nodes\": [\"suggest_schema\"],  # Specify the next node(s)\n",
    "            \"state\": state  # Return the updated state\n",
    "        }\n",
    "    return {\n",
    "        \"next_nodes\": [END],  # End the graph if no valid invoke value is found\n",
    "        \"state\": state  # Return the state as is\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c60521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_message_classifier(state: SessionState):\n",
    "    system_prompt = '''Classification Categories:\n",
    "\n",
    "SummarizeContext\n",
    "The user is asking for a summary of the current context or conversation. Mention in pointswise and easily understandable format. The summary should be mentioned in reason field\n",
    "➤ Examples:\n",
    "\"Can you summarize our conversation so far?\"\n",
    "\"What have we discussed in this session?\"\n",
    "\"Summarize the key points from our chat.\"\n",
    "\n",
    "UpdateContext\n",
    "The user wants to store information in the agent's internal state for future reference.\n",
    "➤ Examples:\n",
    "\"The client's name is John.\"\n",
    "\"We're organizing a conference on June 5th.\"\n",
    "\"Add this to our team knowledge.\"\n",
    "\n",
    "SuggestOrCreateSchema\n",
    "The user is requesting help designing a schema or structured format to extract information.\n",
    "Design a prompt for the next agent to create a schema based on the user's request. mention it in the reason field.\n",
    "➤ Examples:\n",
    "\"Can you create a schema for extracting details from job applications?\"\n",
    "\"Suggest a structure to capture meeting notes.\"\n",
    "\"What format should I use to store bug report info?\"\n",
    "\n",
    "ExtractData\n",
    "The user provides a schema and wants you to apply it to extract structured data from text.\n",
    "design the shcema in the form of json string based on the user request\n",
    "➤ Examples:\n",
    "\"Here's a schema: {name, date, location}. Extract this from the paragraph below.\"\n",
    "\"Use this format and pull details from the email.\"\n",
    "\"extract data with fileds including title, name and age\"\n",
    "\"Apply this structure: {title, author, summary} to the following.\n",
    "\n",
    "## Output Format:\n",
    " {\n",
    "  \"classification\": \"UpdateContext\" | \"SuggestOrCreateSchema\" | \"ExtractData\" | \"SummarizeContext\",\n",
    "  \"reason\": \"Brief explanation to use it as a prompt for the next agent\",\n",
    "  \"schema\": \"The schema to be used for the next agent(used in ExtractData)\",\n",
    "  \"update_context\": \"The context to be updated in the agent's internal state(used in UpdateContext)\",\n",
    "}'''\n",
    "    \n",
    "    query = state[\"messages\"][-1].content\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "        contents=query\n",
    "    )\n",
    "    \n",
    "    \n",
    "    response = response.text\n",
    "    response = json.loads(response[7:-3])\n",
    "    val = response[\"classification\"]\n",
    "    state[\"invoke\"] = val\n",
    "    result = \"create a schema to extract event name and date\"\n",
    "    \n",
    "    if state[\"invoke\"] == \"UpdateContext\":\n",
    "        result = response[\"update_context\"]\n",
    "    elif state[\"invoke\"] == \"SuggestOrCreateSchema\":\n",
    "        result = response[\"reason\"]\n",
    "    elif state[\"invoke\"] == \"SummarizeContext\":\n",
    "        result = response[\"reason\"]\n",
    "    elif state[\"invoke\"] == \"ExtractData\":\n",
    "        result = response[\"schema\"]\n",
    "        \n",
    "    return { **state, \"invoke\": state[\"invoke\"], \"feedback\": [{\"role\": \"assistant\", \"content\": result}] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bf26d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_definer(state: SessionState):\n",
    "    system_prompt = '''Role: You are a Schema Design Agent. Your task is to analyze markdown-formatted data from various file types (e.g., CSVs, PDFs, JSON, slides) and produce a structured schema that accurately represents the data model.\n",
    "\n",
    "      Objective: Extract entities, fields, relationships, and data types from the given content and output a standardized schema (e.g., JSON Schema, Prisma model, or custom format).\n",
    "\n",
    "      Instructions:\n",
    "      1. **Parse Structure**: Analyze tabular, hierarchical, or semantic layouts (e.g., headings, tables, key-value pairs).\n",
    "      2. **Identify Entities and Fields**: Detect entities (e.g., tables/objects) and their fields, data types, and relationships (e.g., primary/foreign keys).\n",
    "      3. **Infer Data Types**: Deduce types (string, number, boolean, date, etc.) from the content.\n",
    "      4. **Preserve Naming**: Use semantic, human-readable names and normalize conventions (e.g., camelCase, snake_case).\n",
    "      5. **Handle Ambiguities**: Make informed guesses and flag uncertainties for review.\n",
    "      6. **No External Assumptions**: Only rely on the provided data.\n",
    "\n",
    "      Output Format: Return the schema in a structured format (e.g., JSON Schema, Prisma schema).\n",
    "\n",
    "      Example Output:\n",
    "      {\n",
    "        \"entities\": [\n",
    "          {\n",
    "            \"name\": \"User\",\n",
    "            \"fields\": [\n",
    "              {\"name\": \"id\", \"type\": \"string\", \"description\": \"Unique identifier\"},\n",
    "              {\"name\": \"email\", \"type\": \"string\"},\n",
    "              {\"name\": \"signupDate\", \"type\": \"date\"}\n",
    "            ]\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Order\",\n",
    "            \"fields\": [\n",
    "              {\"name\": \"orderId\", \"type\": \"string\"},\n",
    "              {\"name\": \"userId\", \"type\": \"string\", \"relation\": \"User.id\"},\n",
    "              {\"name\": \"amount\", \"type\": \"number\"}\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "      '''\n",
    "    \n",
    "    response = requests.post(\n",
    "      server_url + \"/searchData\",\n",
    "      headers={\"Content-Type\": \"application/json\"},\n",
    "      data=json.dumps({\n",
    "          \"collection_id\": state[\"id\"],\n",
    "          \"text\": state[\"feedback\"][-1].content,\n",
    "          \"n_results\": 3,\n",
    "        }),\n",
    "    )\n",
    "    \n",
    "    message = {\n",
    "      \"context\": response.json()[\"results\"][0][\"text\"],\n",
    "      \"user\": state[\"feedback\"][-1].content,\n",
    "    }\n",
    "    \n",
    "    result = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "        contents=str(message)\n",
    "    )\n",
    "    result = result.text[7:-3].replace(\"\\n\", ' ')\n",
    "    \n",
    "    state[\"invoke\"] = \"extract_data\"\n",
    "    \n",
    "    return { **state, \"invoke\": state[\"invoke\"], \"feedback\": [{\"role\": \"assistant\", \"content\": result}] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "be72fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(state: SessionState):\n",
    "    system_prompt = '''Role: You are a Data Extraction Agent. Your task is to extract structured data from the provided chunks of text based on the schema provided by the user.\n",
    "\n",
    "Objective: Use the schema to identify and extract relevant information from the input data and return it in a structured format.\n",
    "\n",
    "Instructions:\n",
    "1. **Understand the Schema**: Parse the schema provided by the user to determine the fields and their expected data types.\n",
    "2. **Extract Data**: Analyze the input text and extract values that match the schema fields.\n",
    "3. **Handle Missing Fields**: If a field is missing in the input data, leave it as null or empty in the output.\n",
    "4. **Preserve Data Integrity**: Ensure the extracted data matches the expected format and type as defined in the schema.\n",
    "5. **No External Assumptions**: Only rely on the provided schema and input data for extraction.\n",
    "6. **If nothing is found, return an empty JSON object.**\n",
    "\n",
    "Output Format:\n",
    "Return the extracted data as a JSON object that adheres to the schema provided by the user.\n",
    "'''\n",
    "\n",
    "    response = requests.post(\n",
    "        server_url + \"/searchData\",\n",
    "        json={\n",
    "            \"collection_id\": state[\"id\"],\n",
    "            \"text\": state[\"feedback\"][-1].content,\n",
    "            \"n_results\": 3,\n",
    "        }\n",
    "    )\n",
    "    response = response.json()\n",
    "    extracted_data = []\n",
    "    \n",
    "    for doc in response[\"results\"]:\n",
    "        extracted_data.append(doc[\"text\"])\n",
    "        \n",
    "    result = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "        contents=str({\n",
    "            \"context\": extract_data,\n",
    "            \"user\": state[\"feedback\"][-1].content,\n",
    "        })\n",
    "    )\n",
    "\n",
    "    result = result.text[7:-3].replace(\"\\n\", ' ')\n",
    "    # result = json.loads(result)\n",
    "        \n",
    "    state[\"invoke\"] = \"done\"\n",
    "    return {\n",
    "        **state,\n",
    "        \"invoke\": state[\"invoke\"],\n",
    "        \"feedback\": [{\"role\": \"assistant\", \"content\": result}],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "43e8c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_schema(state: SessionState):\n",
    "    system_prompt = '''Role: You are a Schema Suggestion Agent. Your task is to analyze the user's input and suggest a schema for data extraction.\n",
    "Objective: Based on the user's request, create a schema that defines the structure and fields for data extraction.\n",
    "Instructions:\n",
    "1. **Understand the User's Request**: Analyze the user's input to identify the type of data they want to extract.\n",
    "2. **Define the Schema**: Create a schema that includes entities, fields, and their data types based on the user's request.\n",
    "3. **Use Standard Formats**: Structure the schema in a standard format (e.g., JSON Schema, Prisma model).\n",
    "4. **Be Specific**: Ensure the schema is specific to the user's request and covers all necessary fields.\n",
    "5. **No External Assumptions**: Only rely on the user's input for schema creation.\n",
    "Output Format:\n",
    "Return the suggested schema as a JSON object that defines the structure for data extraction.\n",
    "Example Output:\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"name\": \"Event\",\n",
    "      \"fields\": [\n",
    "        {\"name\": \"eventName\", \"type\": \"string\"},\n",
    "        {\"name\": \"eventDate\", \"type\": \"date\"},\n",
    "        {\"name\": \"location\", \"type\": \"string\"}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "    \n",
    "    # query = state[\"messages\"][-1].content\n",
    "    \n",
    "    response = requests.post(\n",
    "        server_url + \"/searchData\",\n",
    "        json={\n",
    "            \"collection_id\": state[\"id\"],\n",
    "            \"text\": state[\"feedback\"][-1].content,\n",
    "            \"n_results\": 3,\n",
    "        }\n",
    "    )\n",
    "    response = response.json()\n",
    "    extracted_data = []\n",
    "    \n",
    "    for doc in response[\"results\"]:\n",
    "        extracted_data.append(doc[\"text\"])\n",
    "        \n",
    "    result = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "        contents=str({\n",
    "            \"context\": extract_data,\n",
    "            \"user\": state[\"messages\"][-1].content,\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    result = response.text[7:-3].replace(\"\\n\", ' ')\n",
    "    # result = json.loads(result)\n",
    "    print(result.text[7:-3].replace(\"\\n\", ' '))\n",
    "    # result = \"hello\"    \n",
    "    state[\"invoke\"] = \"extract_data\"\n",
    "    \n",
    "    return { **state, \"invoke\": state[\"invoke\"], \"feedback\": [{\"role\": \"assistant\", \"content\": result}] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b42aaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(SessionState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c2b729b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7d17060c58d0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"interface_agent\", interface_agent)\n",
    "graph_builder.add_node(\"user_message_classifier\", user_message_classifier)\n",
    "graph_builder.add_node(\"schema_definer\", schema_definer)\n",
    "graph_builder.add_node(\"extract_data\", extract_data)\n",
    "graph_builder.add_node(\"suggest_schema\", suggest_schema)\n",
    "\n",
    "graph_builder.set_entry_point(\"interface_agent\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"interface_agent\",\n",
    "    lambda state: interface_agent(state)[\"next_nodes\"],  # Extract next_nodes\n",
    "    {\n",
    "        \"user_message_classifier\": \"user_message_classifier\",\n",
    "        \"schema_definer\": \"schema_definer\",\n",
    "        \"extract_data\": \"extract_data\",\n",
    "        \"suggest_schema\": \"suggest_schema\",\n",
    "        END: END\n",
    "    },\n",
    ")\n",
    "graph_builder.add_edge(\"user_message_classifier\", \"interface_agent\")\n",
    "graph_builder.add_edge(\"schema_definer\", \"interface_agent\")\n",
    "graph_builder.add_edge(\"extract_data\", \"interface_agent\")\n",
    "graph_builder.add_edge(\"suggest_schema\", \"interface_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f2540bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7e3318c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"id\": \"33dc47d9b2ed42f4b769c3d225ea2d4c\",\n",
    "    \"session_name\": \"Test Session\",\n",
    "    \"feedback\": [],\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"suggest me a schema to extract information from the given data about event details\"},\n",
    "        # {'role': 'user', 'content': 'Can you add a new event with name \"Annual Meeting\", date \"2023-10-15\", and location \"New York\"?'},\n",
    "                # {\"role\": \"user\", \"content\": \"extract the event details from the given data, including the event name, date, and location.\"},\n",
    "    ],\n",
    "    \"invoke\": \"message\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "81359bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "message\n",
      "SuggestOrCreateSchema\n",
      "SuggestOrCreateSchema\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2688\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2687\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2688\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2689\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2690\u001b[0m     config,\n\u001b[1;32m   2691\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2692\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2693\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2694\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2695\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2696\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2697\u001b[0m ):\n\u001b[1;32m   2698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2699\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2340\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2340\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2341\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2342\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2343\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2344\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2345\u001b[0m         ):\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    156\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/utils/runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    603\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    604\u001b[0m )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/langgraph/utils/runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 371\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[154], line 52\u001b[0m, in \u001b[0;36msuggest_schema\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     41\u001b[0m     extracted_data\u001b[38;5;241m.\u001b[39mappend(doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     43\u001b[0m result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39mMODEL,\n\u001b[1;32m     45\u001b[0m     config\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mGenerateContentConfig(system_instruction\u001b[38;5;241m=\u001b[39msystem_prompt),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     })\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m[\u001b[38;5;241m7\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# result = json.loads(result)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mtext[\u001b[38;5;241m7\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "output = graph.invoke(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = output[\"feedback\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55843ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/htf/lib/python3.10/site-packages/pydantic/main.py:994\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "json.loads(schema.replace(\"\\n\", ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129b5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6a124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
